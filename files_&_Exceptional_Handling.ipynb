{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2d75c3-33c3-4b7d-b833-846c0efcceec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Discuss the scenarios where multithreading is preferable to multiprocessing and scenarios where\n",
    "# multiprocessing is a better choice.\n",
    "\n",
    "# Multithreading\n",
    "# Multithreading involves running multiple threads within a single process. Threads share the same memory space, which makes communication between threads easier but introduces concerns about race conditions and thread safety.\n",
    "\n",
    "# When Multithreading is Preferable:\n",
    "# I/O-Bound Tasks:\n",
    "\n",
    "# Multithreading is most effective when the program spends a significant amount of time waiting for I/O operations, such as reading/writing files, network communication, or interacting with databases.\n",
    "# Example: A web server handling multiple HTTP requests, where each thread is responsible for handling a single request. Most of the time is spent waiting for responses (e.g., from databases), allowing other threads to execute.\n",
    "# Shared Memory Scenarios:\n",
    "\n",
    "# When tasks need to share a lot of data, multithreading is more efficient since threads share the same memory space, eliminating the overhead of inter-process communication (IPC).\n",
    "# Example: A program that performs computations on a large shared data structure (like a matrix or a large array).\n",
    "# Low Memory Overhead:\n",
    "\n",
    "# Since threads share memory, multithreading requires less memory compared to creating multiple processes, which have their own memory spaces.\n",
    "# Example: In GUI applications, where the main thread is handling user input while worker threads perform background tasks like file loading or image processing.\n",
    "# High-Frequency Context Switching:\n",
    "\n",
    "# When tasks need to frequently switch between them, multithreading has lower overhead compared to multiprocessing due to cheaper context switching.\n",
    "# Example: Real-time or low-latency applications, such as gaming or live-streaming, where responsiveness is critical.\n",
    "# Multiprocessing\n",
    "# Multiprocessing involves creating multiple independent processes, each with its own memory space. This is useful when tasks are CPU-intensive and need to be parallelized across multiple cores.\n",
    "\n",
    "# When Multiprocessing is Preferable:\n",
    "# CPU-Bound Tasks:\n",
    "\n",
    "# Multiprocessing is ideal for tasks that require significant computation and need to utilize multiple CPU cores effectively.\n",
    "# Example: Machine learning model training, image processing, or scientific computations that are highly CPU-intensive.\n",
    "# Avoiding Global Interpreter Lock (GIL):\n",
    "\n",
    "# In Python, the GIL prevents multiple native threads from executing Python bytecode in parallel, which limits the performance of multithreading for CPU-bound tasks. Multiprocessing bypasses the GIL by running processes in separate memory spaces.\n",
    "# Example: A program that performs heavy mathematical calculations or simulations.\n",
    "# Fault Isolation:\n",
    "\n",
    "# Since processes are isolated from one another, multiprocessing is a safer choice when you need to isolate tasks. A crash in one process won’t affect others.\n",
    "# Example: A server running multiple independent services, where a failure in one process should not take down the entire system.\n",
    "# Scalability Across Machines:\n",
    "\n",
    "# Multiprocessing is often more scalable in distributed systems, where each process can run on a separate machine or core without needing shared memory.\n",
    "# Example: Big data applications that distribute tasks across a cluster of machines, such as in Hadoop or Spark.\n",
    "# Memory-Intensive Tasks:\n",
    "\n",
    "# In scenarios where tasks are memory-intensive and require separate memory spaces to avoid bottlenecks, multiprocessing is the better choice.\n",
    "# Example: Video processing tasks, where large video files are split across different processes for simultaneous processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672a17f4-c858-4509-9af1-cd501d1e0cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Describe what a process pool is and how it helps in managing multiple processes efficiently\n",
    "# A process pool is a high-level abstraction used to manage and control a group of worker processes efficiently. Instead of manually creating and managing individual processes, a process pool provides a simplified interface for executing multiple tasks concurrently using a fixed number of processes. This is particularly useful for parallelizing CPU-bound tasks that can run independently across multiple CPU cores.\n",
    "\n",
    "# Key Concepts of a Process Pool:\n",
    "# Fixed Number of Processes:\n",
    "\n",
    "# The pool has a fixed number of worker processes that are created once and reused to execute multiple tasks. The number of processes in the pool typically corresponds to the number of available CPU cores.\n",
    "# Task Queueing:\n",
    "\n",
    "# Tasks are submitted to the pool for execution, and they are added to a task queue. The pool manages the distribution of these tasks among the available worker processes.\n",
    "# Efficient Resource Management:\n",
    "\n",
    "# By limiting the number of processes, a process pool prevents the system from being overwhelmed by too many processes running simultaneously. This ensures efficient CPU and memory usage without the overhead of constantly creating and destroying processes.\n",
    "# Asynchronous Execution:\n",
    "\n",
    "# Tasks can be executed asynchronously, meaning the program can continue running while waiting for the results of the submitted tasks. Once a task completes, the result can be retrieved later, allowing the program to be non-blocking.\n",
    "# Reusability:\n",
    "\n",
    "# Instead of creating new processes for each task (which is computationally expensive), the same processes in the pool are reused for different tasks, reducing the overhead of process creation and destruction.\n",
    "# How a Process Pool Helps Manage Multiple Processes Efficiently:\n",
    "# Reduced Overhead:\n",
    "\n",
    "# Creating and destroying processes frequently is resource-intensive, as each process needs its own memory space, context switching, and OS-level management. A process pool creates a set of processes once and reuses them, thus minimizing the overhead associated with process management.\n",
    "# Load Balancing:\n",
    "\n",
    "# The process pool efficiently manages the distribution of tasks among worker processes. As each process finishes its task, it picks up the next available task from the queue. This dynamic load balancing ensures that all available CPU cores are utilized optimally.\n",
    "# Concurrency Control:\n",
    "\n",
    "# By controlling the number of worker processes, a process pool prevents excessive concurrent processes that can slow down the system or lead to resource contention. The pool ensures a balanced use of system resources without overwhelming the system with too many processes.\n",
    "# Parallel Execution:\n",
    "\n",
    "# A process pool allows tasks to be executed in parallel across multiple CPU cores, leading to significant performance improvements for CPU-bound tasks. Each process runs independently, utilizing its own CPU core.\n",
    "# Simplified API:\n",
    "\n",
    "# Libraries like Python’s multiprocessing.Pool or similar implementations in other languages provide a simplified interface for managing processes. Developers do not have to worry about the details of process creation, destruction, or inter-process communication (IPC). Instead, they can submit tasks to the pool and retrieve results easily.\n",
    "# Common Use Cases for Process Pools:\n",
    "# Parallelizing CPU-bound computations:\n",
    "\n",
    "# Tasks that require heavy computation, such as mathematical modeling, data analysis, or machine learning, can be distributed across multiple processes using a pool.\n",
    "# Batch Processing:\n",
    "\n",
    "# When a large number of independent tasks need to be processed, such as image processing or video transcoding, process pools can be used to distribute these tasks across CPU cores.\n",
    "# Web Scraping:\n",
    "\n",
    "# In web scraping tasks, multiple URLs can be scraped concurrently by distributing them across the processes in a pool.\n",
    "\n",
    "import multiprocessing\n",
    "import time\n",
    "\n",
    "# Function to be executed by each process\n",
    "def worker_function(x):\n",
    "    time.sleep(1)  # Simulate a time-consuming task\n",
    "    return x * x\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Create a pool of 4 worker processes\n",
    "    with multiprocessing.Pool(4) as pool:\n",
    "        # Distribute tasks to the pool\n",
    "        results = pool.map(worker_function, range(10))\n",
    "    \n",
    "    print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a6b6e3-9d36-49fa-aafd-18b1805fc4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Explain what multiprocessing is and why it is used in Python programs.\n",
    "# What is Multiprocessing?\n",
    "# Processes: A process is an instance of a running program. Each process in an operating system has its own memory space, code, data, and system resources.\n",
    "# Concurrency and Parallelism: Multiprocessing enables parallelism, where different processes can run simultaneously on separate CPU cores, as opposed to concurrency (often achieved through multithreading), where multiple tasks are scheduled to run in overlapping periods but may not run at the same time.\n",
    "# CPU Cores: Multiprocessing takes advantage of multiple CPU cores in a machine to run independent tasks at the same time, effectively speeding up CPU-bound programs by distributing work across cores.\n",
    "# Why Multiprocessing is Used in Python Programs:\n",
    "# 1. Bypassing the Global Interpreter Lock (GIL):\n",
    "# GIL in Python:\n",
    "# Python’s GIL is a mechanism that prevents multiple native threads from executing Python bytecode simultaneously. It’s a lock that ensures only one thread executes Python code at a time, limiting the performance benefits of multithreading in CPU-bound tasks.\n",
    "# How Multiprocessing Helps:\n",
    "# Multiprocessing creates independent processes, each with its own memory space and Python interpreter instance. This means each process can run in parallel on a different CPU core, completely bypassing the GIL.\n",
    "# As a result, Python programs using multiprocessing can fully utilize the available CPU cores, making them faster for computationally intensive tasks.\n",
    "# 2. Parallelizing CPU-Bound Tasks:\n",
    "# CPU-Bound Tasks:\n",
    "\n",
    "# Tasks that require significant computation, such as numerical calculations, machine learning model training, image processing, or data transformation, are CPU-bound because they are limited by the speed of the CPU.\n",
    "# Benefits of Parallel Execution:\n",
    "\n",
    "# Multiprocessing divides these tasks into smaller, independent tasks that can be executed in parallel on different CPU cores, resulting in much faster execution.\n",
    "# Example: A program performing matrix multiplication on large datasets can distribute parts of the computation to different processes.\n",
    "# 3. Isolation and Stability:\n",
    "# Process Isolation:\n",
    "# Each process runs in its own memory space, meaning it is isolated from other processes. This provides better stability because a crash in one process does not affect the others.\n",
    "# Fault Tolerance:\n",
    "# If one process encounters an error or crashes, it doesn’t bring down the entire program, unlike in multithreading, where thread failures can lead to unpredictable behavior.\n",
    "# 4. Handling Multiple Independent Tasks:\n",
    "# Task Parallelism:\n",
    "# When multiple independent tasks need to be executed, such as processing files, images, or network requests, multiprocessing allows these tasks to be distributed among different processes, running them simultaneously.\n",
    "# Example: A data pipeline that processes large datasets by splitting them into chunks and processing them concurrently with multiple processes.\n",
    "# 5. Efficient Use of Multi-Core Processors:\n",
    "# Multi-Core CPUs:\n",
    "\n",
    "# Modern CPUs have multiple cores, and multiprocessing ensures that Python programs can take full advantage of these cores by running processes in parallel on different cores.\n",
    "# Maximizing CPU Utilization:\n",
    "\n",
    "# Without multiprocessing, a program running on a single core would leave the remaining cores idle. Multiprocessing helps to maximize CPU utilization by distributing tasks across available cores.\n",
    "# How Multiprocessing Works in Python:\n",
    "# The Python multiprocessing module provides a high-level interface for working with processes. It allows you to create new processes, share data between them, and communicate using pipes or queues.\n",
    "\n",
    "# Basic Example:\n",
    "# python\n",
    "# Copy code\n",
    "# import multiprocessing\n",
    "\n",
    "# def worker_function(x):\n",
    "#     return x * x\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Create a Pool of processes\n",
    "#     pool = multiprocessing.Pool(4)  # 4 processes\n",
    "#     # Distribute the work across processes\n",
    "#     result = pool.map(worker_function, range(10))\n",
    "    \n",
    "#     print(result)\n",
    "# Key Components of Python's Multiprocessing Module:\n",
    "# Process Class:\n",
    "\n",
    "# The multiprocessing.Process class is used to create a new process that runs a target function in parallel with the main program.\n",
    "\n",
    "from multiprocessing import Process\n",
    "\n",
    "def print_square(num):\n",
    "    print(num * num)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    p = Process(target=print_square, args=(5,))\n",
    "    p.start()  # Starts the process\n",
    "    p.join()   # Wait for the process to complete\n",
    "    \n",
    "# Pool Class:\n",
    "\n",
    "# The multiprocessing.Pool class creates a pool of worker processes. You can distribute tasks to these processes, which are executed concurrently.\n",
    "# The map() method splits a task and distributes it across the pool’s processes.\n",
    "# Communication:\n",
    "\n",
    "# Queues and Pipes can be used to send and receive messages between processes, allowing them to communicate and share results.\n",
    "# Shared Memory:\n",
    "\n",
    "# Shared memory objects like Value and Array allow multiple processes to share and modify data safely.\n",
    "# Advantages of Multiprocessing in Python:\n",
    "# True Parallelism:\n",
    "\n",
    "# Multiprocessing allows Python programs to achieve true parallelism by utilizing multiple CPU cores and bypassing the GIL.\n",
    "# Scalability:\n",
    "\n",
    "# Programs that can be split into independent tasks scale well with multiprocessing, allowing them to handle larger datasets or more complex computations efficiently.\n",
    "# Fault Isolation:\n",
    "\n",
    "# Process isolation ensures that issues in one process do not affect others, improving the robustness of the program.\n",
    "# Simplified API:\n",
    "\n",
    "# The multiprocessing module provides an easy-to-use API for creating and managing processes, making it accessible to developers without needing low-level process management.\n",
    "# Limitations of Multiprocessing:\n",
    "# Memory Overhead:\n",
    "\n",
    "# Each process has its own memory space, so memory usage can increase significantly when multiple processes are created, unlike threads which share memory.\n",
    "# Communication Overhead:\n",
    "\n",
    "# Communicating between processes requires inter-process communication (IPC) mechanisms like pipes or queues, which can introduce overhead compared to shared memory in threads.\n",
    "# Slower for I/O-Bound Tasks:\n",
    "\n",
    "# For I/O-bound tasks (e.g., network requests, file operations), multithreading may be more efficient than multiprocessing, since these tasks spend most of their time waiting rather than using CPU cycles.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368a299a-9aa0-4231-a14e-6122ae480453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Write a Python program using multithreading where one thread adds numbers to a list, and another\n",
    "# thread removes numbers from the list. Implement a mechanism to avoid race conditions using\n",
    "# threading.Lock.\n",
    "# Here’s an implementation of the program using threading and threading.Lock:\n",
    "\n",
    "\n",
    "import threading\n",
    "import time\n",
    "import random\n",
    "\n",
    "\n",
    "shared_list = []\n",
    "\n",
    "\n",
    "list_lock = threading.Lock()\n",
    "\n",
    "def add_numbers():\n",
    "    \"\"\"Function to add numbers to the list.\"\"\"\n",
    "    for i in range(10):\n",
    "        time.sleep(random.uniform(0.1, 0.5)) \n",
    "        with list_lock:\n",
    "            number = random.randint(1, 100)\n",
    "            shared_list.append(number)\n",
    "            print(f\"Added {number} to the list. List now: {shared_list}\")\n",
    "\n",
    "def remove_numbers():\n",
    "    \"\"\"Function to remove numbers from the list.\"\"\"\n",
    "    for i in range(10):\n",
    "        time.sleep(random.uniform(0.1, 0.5)) \n",
    "        with list_lock:\n",
    "            if shared_list:\n",
    "                removed_number = shared_list.pop(0)\n",
    "                print(f\"Removed {removed_number} from the list. List now: {shared_list}\")\n",
    "            else:\n",
    "                print(\"List is empty, nothing to remove.\")\n",
    "\n",
    "\n",
    "add_thread = threading.Thread(target=add_numbers)\n",
    "remove_thread = threading.Thread(target=remove_numbers)\n",
    "\n",
    "\n",
    "add_thread.start()\n",
    "remove_thread.start()\n",
    "\n",
    "\n",
    "add_thread.join()\n",
    "remove_thread.join()\n",
    "\n",
    "print(\"Final state of the list:\", shared_list)\n",
    "\n",
    "\n",
    "Added 85 to the list. List now: [85]\n",
    "Removed 85 from the list. List now: []\n",
    "Added 12 to the list. List now: [12]\n",
    "Added 78 to the list. List now: [12, 78]\n",
    "Removed 12 from the list. List now: [78]\n",
    "Removed 78 from the list. List now: []\n",
    "...\n",
    "Final state of the list: []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0453112a-c733-4487-9afe-8d8e560a313f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Describe the methods and tools available in Python for safely sharing data between threads and\n",
    "# processes.\n",
    "\n",
    "# 1. Methods and Tools for Sharing Data Between Threads:\n",
    "# In Python, threads run in the same memory space, which allows them to access and modify shared data. However, this shared access can lead to race conditions if not handled carefully. Below are the common methods and tools used to safely share data between threads:\n",
    "\n",
    "# a. Threading Locks (threading.Lock)\n",
    "# A lock ensures that only one thread can access shared data at a time, preventing race conditions.\n",
    "# The thread acquires the lock before accessing the shared resource, and releases it when done, so that other threads can proceed.\n",
    "\n",
    "import threading\n",
    "\n",
    "lock = threading.Lock()\n",
    "\n",
    "def critical_section():\n",
    "    with lock:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5146ec9-cfb1-43cc-93c1-5c0e04337258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Discuss why it’s crucial to handle exceptions in concurrent programs and the techniques available for\n",
    "# doing so.\n",
    "# 1. Ensuring Reliability and Stability\n",
    "# Preventing Crashes: Unhandled exceptions can lead to application crashes, which may result in data loss or corruption. Proper exception handling ensures that the program can gracefully recover from errors.\n",
    "# Maintaining State: Concurrent programs often maintain shared state across multiple threads or processes. If an exception occurs in one part of the program, it can affect the entire system if not handled properly.\n",
    "# 2. Resource Management\n",
    "# Avoiding Resource Leaks: Exceptions can cause resources (like file handles, database connections, etc.) to be left open if not properly managed. Handling exceptions allows for proper cleanup of resources.\n",
    "# Preventing Deadlocks: In concurrent programs, failing to handle exceptions may lead to deadlocks, where two or more threads are waiting indefinitely for resources held by each other.\n",
    "# 3. Debugging and Monitoring\n",
    "# Providing Insight into Failures: Exception handling allows developers to log errors, making it easier to understand and diagnose problems in concurrent systems.\n",
    "# Centralized Error Management: It provides a systematic approach to handle errors, which can be monitored and analyzed, making it easier to enhance the system over time.\n",
    "# 4. User Experience\n",
    "# Graceful Degradation: Instead of crashing or behaving unpredictably, programs can inform the user about the issue and possibly offer alternatives or retries.\n",
    "# Error Propagation: Proper handling allows errors to be communicated effectively across threads or processes, ensuring that the relevant parts of the system can respond appropriately.\n",
    "# Techniques for Handling Exceptions in Concurrent Programs\n",
    "# Try-Catch Blocks\n",
    "\n",
    "# Use traditional try-catch mechanisms to catch exceptions in individual threads. This allows specific handling for errors that occur within those threads.\n",
    "# Thread-Specific Exception Handling\n",
    "\n",
    "# Many concurrent programming frameworks (like Java’s Thread or Python’s concurrent.futures) allow for thread-specific exception handling where you can define what should happen when an exception occurs in a thread.\n",
    "# Error Reporting and Aggregation\n",
    "\n",
    "# Implement error reporting systems where exceptions from different threads can be logged or reported to a central location. This is useful for monitoring and debugging.\n",
    "# Future and Callback Patterns\n",
    "\n",
    "# Use futures or callbacks to handle results from concurrent tasks. This pattern allows you to manage exceptions in asynchronous calls more effectively. If a task fails, the exception can be propagated back to the caller through the future or callback.\n",
    "# Cancellation and Timeouts\n",
    "\n",
    "# Implement mechanisms to cancel tasks that are taking too long or are in an error state. This can help prevent cascading failures in a system.\n",
    "# Using Supervisory Patterns\n",
    "\n",
    "# In some frameworks (like Erlang or Akka), a supervisory pattern can be used where one part of the system is responsible for monitoring and restarting failed components.\n",
    "# Retry Logic\n",
    "\n",
    "# Implement retry mechanisms for operations that may fail due to transient issues. This can help improve the robustness of the application.\n",
    "# Thread Pools\n",
    "\n",
    "# Using thread pools allows centralized management of threads, including handling exceptions in a controlled manner, which can help with resource management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ff9f62c-fe5a-4b7f-8150-ec501dc23769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factorial of 1 is 1\n",
      "Factorial of 2 is 2\n",
      "Factorial of 7 is 5040\n",
      "Factorial of 6 is 720\n",
      "Factorial of 5 is 120\n",
      "Factorial of 4 is 24\n",
      "Factorial of 3 is 6\n",
      "Factorial of 9 is 362880\n",
      "Factorial of 8 is 40320\n",
      "Factorial of 10 is 3628800\n"
     ]
    }
   ],
   "source": [
    "# 7. Create a program that uses a thread pool to calculate the factorial of numbers from 1 to 10 concurrently.\n",
    "# Use concurrent.futures.ThreadPoolExecutor to manage the threads.\n",
    "\n",
    "import concurrent.futures\n",
    "import math\n",
    "\n",
    "\n",
    "def factorial(n):\n",
    "    return math.factorial(n)\n",
    "\n",
    "def main():\n",
    " \n",
    "    numbers = range(1, 11)\n",
    "\n",
    "   \n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "\n",
    "        results = {executor.submit(factorial, num): num for num in numbers}\n",
    "\n",
    "    \n",
    "        for future in concurrent.futures.as_completed(results):\n",
    "            num = results[future]\n",
    "            try:\n",
    "                result = future.result()\n",
    "                print(f\"Factorial of {num} is {result}\")\n",
    "            except Exception as exc:\n",
    "                print(f\"{num} generated an exception: {exc}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159ecd01-a10d-481a-98f9-e52df70edfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Create a Python program that uses multiprocessing.Pool to compute the square of numbers from 1 to 10 in\n",
    "# parallel. Measure the time taken to perform this computation using a pool of different sizes (e.g., 2, 4, 8\n",
    "# processes).\n",
    "import multiprocessing\n",
    "import time\n",
    "\n",
    "# Function to compute the square of a number\n",
    "def square(n):\n",
    "    return n * n\n",
    "\n",
    "# Function to compute squares in parallel and measure the time taken\n",
    "def compute_squares_with_pool_size(pool_size):\n",
    "    numbers = range(1, 11)\n",
    "    \n",
    "  \n",
    "    start_time = time.time()\n",
    "    \n",
    "   \n",
    "    with multiprocessing.Pool(pool_size) as pool:\n",
    "        results = pool.map(square, numbers)\n",
    "\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    print(f\"Pool Size: {pool_size}, Results: {results}, Time Taken: {end_time - start_time:.4f} seconds\")\n",
    "\n",
    "def main():\n",
    " \n",
    "    for pool_size in [2, 4, 8]:\n",
    "        compute_squares_with_pool_size(pool_size)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e015a077-393b-462e-aa02-fe892a90b3b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
